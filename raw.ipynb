{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(\"HOME:\", HOME)\n",
    "\n",
    "!pip install -q 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision==0.23.0\n",
    "!mkdir -p {HOME}/weights\n",
    "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P {HOME}/weights\n",
    "\n",
    "import os\n",
    "\n",
    "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
    "print(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))\n",
    "\n",
    "import torch\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_TYPE = \"vit_h\"\n",
    "\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)\n",
    "\n",
    "mask_predictor = SamPredictor(sam)\n",
    "import os\n",
    "\n",
    "IMAGE_NAME = \"Melatonin.png\"\n",
    "IMAGE_PATH = os.path.join(HOME, IMAGE_NAME)\n",
    "\n",
    "import base64\n",
    "\n",
    "def encode_image(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "    encoded = str(base64.b64encode(image_bytes), 'utf-8')\n",
    "    return \"data:image/jpg;base64,\"+encoded\n",
    "\n",
    "IS_COLAB = True\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "\n",
    "from jupyter_bbox_widget import BBoxWidget\n",
    "\n",
    "widget = BBoxWidget()\n",
    "widget.image = encode_image(IMAGE_PATH)\n",
    "widget\n",
    "\n",
    "widget.bboxes\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# default_box is going to be used if you will not draw any box on image above\n",
    "default_box = {'x': 68, 'y': 247, 'width': 555, 'height': 678, 'label': ''}\n",
    "\n",
    "box = widget.bboxes[0] if widget.bboxes else default_box\n",
    "box = np.array([\n",
    "    box['x'],\n",
    "    box['y'],\n",
    "    box['x'] + box['width'],\n",
    "    box['y'] + box['height']\n",
    "])\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "image_bgr = cv2.imread(IMAGE_PATH)\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask_predictor.set_image(image_rgb)\n",
    "\n",
    "masks, scores, logits = mask_predictor.predict(\n",
    "    box=box,\n",
    "    multimask_output=True\n",
    ")\n",
    "\n",
    "box_annotator = sv.BoxAnnotator(color=sv.Color.RED, color_lookup=sv.ColorLookup.INDEX)\n",
    "mask_annotator = sv.MaskAnnotator(color=sv.Color.RED, color_lookup=sv.ColorLookup.INDEX)\n",
    "\n",
    "detections = sv.Detections(\n",
    "    xyxy=sv.mask_to_xyxy(masks=masks),\n",
    "    mask=masks\n",
    ")\n",
    "detections = detections[detections.area == np.max(detections.area)]\n",
    "\n",
    "source_image = box_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
    "segmented_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
    "\n",
    "sv.plot_images_grid(\n",
    "    images=[source_image, segmented_image],\n",
    "    grid_size=(1, 2),\n",
    "    titles=['source image', 'segmented image']\n",
    ")\n",
    "\n",
    "import supervision as v\n",
    "\n",
    "sv.plot_images_grid(\n",
    "    images=masks,\n",
    "    grid_size=(1, 4),\n",
    "    size=(16, 4)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
